{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a40da9f-c0f7-42bc-ac8d-c17bb808aac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3238786121.py, line 147)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 147\u001b[1;36m\u001b[0m\n\u001b[1;33m    indices = np.arange(left_X.shape[0])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter import simpledialog\n",
    "import tkinter\n",
    "import numpy as np\n",
    "from tkinter import filedialog\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn_extensions.extreme_learning_machines.elm import GenELMClassifier\n",
    "from sklearn_extensions.extreme_learning_machines.random_layer import RBFRandomLayer, MLPRandomLayer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import keras.layers\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from keras.layers import Bidirectional\n",
    "main = tkinter.Tk()\n",
    "main.title(\"Automatic Detection of Genetic Diseases in Pediatric Age Using Pupillometry\")\n",
    "main.geometry(\"1300x1200\")\n",
    "\n",
    "global filename\n",
    "\n",
    "global classifier\n",
    "global left_X_train, left_X_test, left_y_train, left_y_test\n",
    "global right_X_train, right_X_test, right_y_train, right_y_test\n",
    "\n",
    "global left_X, left_Y\n",
    "\n",
    "global left_pupil\n",
    "global right_pupil\n",
    "global count\n",
    "global left\n",
    "global right\n",
    "global ids\n",
    "global left_svm_acc\n",
    "global right_svm_acc\n",
    "global left_classifier\n",
    "global right_classifier\n",
    "global classifier\n",
    "global ensemble_acc\n",
    "global elm_acc\n",
    "global lstm_acc,bilstm_acc\n",
    "\n",
    "def upload():\n",
    "    global filename\n",
    "    filename = filedialog.askdirectory(initialdir = \".\")\n",
    "    pathlabel.config(text=filename)\n",
    "    text.delete('1.0', END)\n",
    "    text.insert(END,'Pupillometric  dataset loaded\\n')\n",
    "\n",
    "def filtering():\n",
    "    global left_pupil\n",
    "    global right_pupil\n",
    "    global count\n",
    "    global left\n",
    "    global right\n",
    "    global ids\n",
    "    left_pupil = []\n",
    "    right_pupil = []\n",
    "    count = 0\n",
    "    left = 'Patient_ID,MAX,MIN,DELTA,CH,LATENCY,MCV,label\\n'\n",
    "    right = 'Patient_ID,MAX,MIN,DELTA,CH,LATENCY,MCV,label\\n'\n",
    "    ids = 1\n",
    "    for root, dirs, directory in os.walk('dataset'):\n",
    "        for i in range(len(directory)):\n",
    "            filedata = open('dataset/'+directory[i], 'r')\n",
    "            lines = filedata.readlines()\n",
    "            left_pupil.clear()\n",
    "            right_pupil.clear()\n",
    "            count = 0\n",
    "            for line in lines: \n",
    "                line = line.strip()\n",
    "                arr = line.split(\"\\t\")\n",
    "                if len(arr) == 8:\n",
    "                    if arr[7] == '.....':\n",
    "                        left_pupil.append(float(arr[3].strip()))\n",
    "                        right_pupil.append(float(arr[6].strip()))\n",
    "                        count = count + 1;\n",
    "                        if count == 100:\n",
    " \n",
    "                             left_minimum = min(left_pupil)\n",
    "                             right_minimum = min(right_pupil)\n",
    "                             left_maximum = max(left_pupil)\n",
    "                             right_maximum = max(right_pupil)\n",
    "                             left_delta =  left_maximum - left_minimum\n",
    "                             right_delta = right_maximum - right_minimum\n",
    "                             left_CH = left_delta / left_maximum\n",
    "                             right_CH = right_delta / right_maximum\n",
    "                             latency = 0.5\n",
    "                             left_MCV = left_delta/(left_minimum - latency)\n",
    "                             right_MCV = right_delta/(right_minimum - latency)\n",
    "                             count = 0\n",
    "                             left_pupil.clear()\n",
    "                             right_pupil.clear()\n",
    "                             if left_minimum > 500 and left_maximum > 500: \n",
    "                                left+=str(ids)+\",\"+str(left_maximum)+\",\"+str(left_minimum)+\",\"+str(left_delta)+\",\"+str(left_CH)+\",\"+str(latency)+\",\"+str(left_MCV)+\",1\\n\"\n",
    "                             else:\n",
    "                                left+=str(ids)+\",\"+str(left_maximum)+\",\"+str(left_minimum)+\",\"+str(left_delta)+\",\"+str(left_CH)+\",\"+str(latency)+\",\"+str(left_MCV)+\",0\\n\"\n",
    "                             if right_minimum > 500 and right_maximum > 500:\n",
    "                                right+=str(ids)+\",\"+str(right_maximum)+\",\"+str(right_minimum)+\",\"+str(right_delta)+\",\"+str(right_CH)+\",\"+str(latency)+\",\"+str(right_MCV)+\",1\\n\"\n",
    "                             else:\n",
    "                                right+=str(ids)+\",\"+str(right_maximum)+\",\"+str(right_minimum)+\",\"+str(right_delta)+\",\"+str(right_CH)+\",\"+str(latency)+\",\"+str(right_MCV)+\",0\\n\"\n",
    "                             ids = ids + 1\n",
    " \n",
    "            filedata.close()\n",
    "    \n",
    "    text.delete('1.0', END)\n",
    "    text.insert(END,'Features filteration process completed\\n')\n",
    "    text.insert(END,'Total patients found in dataset : '+str(ids)+\"\\n\")\n",
    "    \n",
    "def featuresExtraction():\n",
    "    f = open(\"left.txt\", \"w\")\n",
    "    f.write(left)\n",
    "    f.close()\n",
    "    f = open(\"right.txt\", \"w\")\n",
    "    f.write(right)\n",
    "    f.close()\n",
    "    text.delete('1.0', END)\n",
    "    text.insert(END,'Both eye pupils extracted features saved inside left.txt and right.txt files \\n')\n",
    "    text.insert(END,\"Extracted features are \\nPatient ID, MAX, MIN, Delta, CH, Latency, MDV, CV and MCV\\n\")\n",
    "\n",
    "def featuresReduction():\n",
    "    text.delete('1.0', END)\n",
    "    global left_X, left_Y\n",
    "    global left_X_train, left_X_test, left_y_train, left_y_test\n",
    "    global right_X_train, right_X_test, right_y_train, right_y_test\n",
    "    left_pupil =  pd.read_csv('left.txt')\n",
    "    right_pupil =  pd.read_csv('right.txt')\n",
    "    cols = left_pupil.shape[1]\n",
    "\n",
    "    left_X = left_pupil.values[:, 1:(cols-1)] \n",
    "    left_Y = left_pupil.values[:, (cols-1)]\n",
    "\n",
    "    right_X = right_pupil.values[:, 1:(cols-1)] \n",
    " \n",
    "right_Y = right_pupil.values[:, (cols-1)]\n",
    "\n",
    "    indices = np.arange(left_X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    left_X = left_X[indices]\n",
    "    left_Y = left_Y[indices]\n",
    "\n",
    "    indices = np.arange(right_X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    right_X = right_X[indices]\n",
    "    right_Y = right_Y[indices]\n",
    "\n",
    "    left_X = normalize(left_X)\n",
    "    right_X = normalize(right_X)\n",
    "    \n",
    "\n",
    "    left_X_train, left_X_test, left_y_train, left_y_test = train_test_split(left_X, left_Y, test_size = 0.2,random_state=42)\n",
    "    right_X_train, right_X_test, right_y_train, right_y_test = train_test_split(right_X, right_Y, test_size = 0.2,random_state=42)\n",
    "\n",
    "    text.insert(END,\"Left pupil features training size : \"+str(len(left_X_train))+\" & testing size : \"+str(len(left_X_test))+\"\\n\")\n",
    "    text.insert(END,\"Right pupil features training size : \"+str(len(right_X_train))+\" & testing size : \"+str(len(right_X_test))+\"\\n\")\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Diameter')\n",
    "    plt.plot(left_pupil['MAX'], 'ro-', color = 'indigo')\n",
    "\n",
    "    plt.plot(right_pupil['MAX'], 'ro-', color = 'green')\n",
    "    plt.legend(['Left Pupil', 'Right Pupil'], loc='upper left')\n",
    "    plt.title('Pupil Diameter Graph')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def prediction(X_test, cls): \n",
    "    y_pred = cls.predict(X_test) \n",
    "    for i in range(len(X_test)):\n",
    "      print(\"X=%s, Predicted=%s\" % (X_test[i], y_pred[i]))\n",
    "    return y_pred \n",
    "\t\n",
    "\n",
    "    \n",
    "    \n",
    "def rightSVM():\n",
    "    global right_classifier\n",
    "    text.delete('1.0', END)\n",
    "    global right_svm_acc\n",
    "    temp = []\n",
    "    for i in range(len(right_y_test)):\n",
    "        temp.append(right_y_test[i])\n",
    "    temp = np.asarray(temp)    \n",
    "    right_classifier = svm.SVC()\n",
    "    right_classifier.fit(right_X_train, right_y_train)\n",
    "    text.insert(END,\"Right pupil SVM Prediction Results\\n\") \n",
    "    prediction_data = prediction(right_X_test, right_classifier) \n",
    "\n",
    "    right_svm_acc = accuracy_score(temp,prediction_data)*100\n",
    "    text.insert(END,\"Right pupil SVM Accuracy : \"+str(right_svm_acc)+\"\\n\")\n",
    "\n",
    "    cm = confusion_matrix(temp, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    text.insert(END,'Right pupil SVM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Right pupil SVM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "\n",
    "def leftSVM():\n",
    "    global left_classifier\n",
    "    text.delete('1.0', END)\n",
    "    global left_svm_acc\n",
    "    temp = []\n",
    "    for i in range(len(left_y_test)):\n",
    "        temp.append(left_y_test[i])\n",
    "    temp = np.asarray(temp) \n",
    "    left_classifier = svm.SVC(kernel='rbf', class_weight='balanced', probability=True)\n",
    "    left_classifier.fit(left_X_train, left_y_train)\n",
    "    text.insert(END,\"Left pupil SVM Prediction Results\\n\") \n",
    "    prediction_data = prediction(left_X_test, left_classifier) \n",
    "    left_svm_acc = accuracy_score(temp,prediction_data)*100\n",
    "    text.insert(END,\"Left pupil SVM Accuracy : \"+str(left_svm_acc)+\"\\n\")\n",
    "\n",
    "    cm = confusion_matrix(temp, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1]) \n",
    "    text.insert(END,'Left pupil SVM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Left pupil SVM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "\n",
    "def ensemble():\n",
    "\n",
    "    global classifier\n",
    "    global ensemble_acc\n",
    "    text.delete('1.0', END)\n",
    "\n",
    "    trainX = np.concatenate((right_X_train, left_X_train))\n",
    "    trainY = np.concatenate((right_y_train, left_y_train))\n",
    "\n",
    "    testX = np.concatenate((right_X_test, left_X_test))\n",
    "    testY = np.concatenate((right_y_test, left_y_test))\n",
    "\n",
    "    left_classifier = svm.SVC(kernel='linear', class_weight='balanced', probability=True)\n",
    "    right_classifier = svm.SVC(kernel='linear', class_weight='balanced', probability=True)\n",
    "\n",
    "    temp = []\n",
    "    for i in range(len(testY)):\n",
    "        temp.append(testY[i])\n",
    "    temp = np.asarray(temp) \n",
    "\n",
    "    classifier = VotingClassifier(estimators=[\n",
    "         ('SVMLeft', left_classifier), ('SVMRight', right_classifier)], voting='hard')\n",
    "    classifier.fit(trainX, trainY)\n",
    "    text.insert(END,\"Optimized Ensemble Prediction Results\\n\") \n",
    "    prediction_data = prediction(testX, classifier) \n",
    "    ensemble_acc =  (accuracy_score(temp,prediction_data)*100)\n",
    "    text.insert(END,\"Ensemble OR Accuracy : \"+str(ensemble_acc)+\"\\n\")\n",
    "\n",
    "    cm = confusion_matrix(temp, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    text.insert(END,'Right pupil Ensemble OR SVM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Right pupil Ensemble OR SVM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "\n",
    "def runLSTM():\n",
    "    global lstm_acc\n",
    "    global left_X, left_Y\n",
    "\n",
    "    Y = left_Y.reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    Y = encoder.fit_transform(Y)\n",
    "    X = left_X.reshape((left_X.shape[0], left_X.shape[1], 1))\n",
    "    print(Y)\n",
    "    print(X.shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.LSTM(32,input_shape=(X.shape[1], 1)))#defining LSTM with input dataset size and number of filters as 32 for first layer\n",
    "    model.add(Dropout(0.5)) \n",
    "#while filtering dataset Dropout will remove all unrelated or irrelevant dataset and hold only important features from dataset\n",
    "    model.add(Dense(32, activation='relu'))\n",
    " #creating another layer with 32 filetrs\n",
    "    model.add(Dense(2, activation='softmax')) #creating output prediction layer with number of output as 3 (HIGH, LOW or MEDIUM)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "#compiling the model and asking to calculate accuracy for each iteration\n",
    "    hist = model.fit(X, Y, verbose=2, batch_size=5, epochs=10)\n",
    "#start training model with batch size 5 and epoch as 100 with X and Y input data\n",
    "    accuracy = hist.history\n",
    "    acc = accuracy['accuracy']                \n",
    "    lstm_acc = acc[9] * 100\n",
    "    text.insert(END,\"\\nLSTM Accuracy : \"+str(lstm_acc)+\"\\n\\n\")\n",
    "    text.insert(END,'LSTM Model Summary can be seen in black console for layer details\\n')\n",
    "    print(model.summary())\n",
    "    prediction_data = model.predict(X) \n",
    "    temp = Y.argmax(axis=1)\n",
    "    prediction_data = prediction_data.argmax(axis=1)\n",
    "    cm = confusion_matrix(temp, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    text.insert(END,'Right pupil LSTM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Right pupil LSTM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "    \n",
    "\n",
    "def runBILSTM():\n",
    "    global bilstm_acc\n",
    "    global left_X, left_Y\n",
    "\n",
    "    Y = left_Y.reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    Y = encoder.fit_transform(Y)\n",
    "    X = left_X.reshape((left_X.shape[0], left_X.shape[1], 1))\n",
    "    print(Y)\n",
    "    print(X.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(keras.layers.LSTM(64, return_sequences=True,input_shape=(X.shape[1], 1))))\n",
    "    model.add(Bidirectional(keras.layers.LSTM(32, return_sequences=True)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "#compiling the model and asking to calculate accuracy for each iteration\n",
    "    hist = model.fit(X, Y, verbose=2, batch_size=5, epochs=10)\n",
    "#start training model with batch size 5 and epoch as 100 with X and Y input data\n",
    "    accuracy = hist.history\n",
    "    acc = accuracy['accuracy']                \n",
    "    bilstm_acc = acc[9] * 100\n",
    "    text.insert(END,\"\\nBI-LSTM Accuracy : \"+str(bilstm_acc)+\"\\n\\n\")\n",
    "    text.insert(END,'Bi-LSTM Model Summary can be seen in black console for layer details\\n')\n",
    "    print(model.summary())\n",
    "\n",
    "    prediction_data = model.predict(X)\n",
    "    temp = Y.argmax(axis=1)\n",
    "    prediction_data = prediction_data.argmax(axis=1)\n",
    "    cm = confusion_matrix(temp, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    text.insert(END,'Right pupil BI-LSTM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Right pupil BI-LSTM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "\n",
    "def predict():\n",
    "    text.delete('1.0', END)\n",
    "    filename = filedialog.askopenfilename(initialdir = \"testData\")\n",
    "    test = pd.read_csv(filename)\n",
    "    test = test.values[:, 0:7]\n",
    "    total = len(test)\n",
    "    text.insert(END,filename+\" test file loaded\\n\");\n",
    "    y_pred = classifier.predict(test)\n",
    "    for i in range(len(test)):\n",
    "        print(str(y_pred[i]))\n",
    "        if str(y_pred[i]) == '0.0':\n",
    "            text.insert(END,\"X=%s, Predicted = %s\" % (test[i], 'No disease detected')+\"\\n\\n\")\n",
    "        else:\n",
    "            text.insert(END,\"X=%s, Predicted = %s\" % (test[i], 'Disease detected')+\"\\n\\n\")\n",
    "\n",
    "\n",
    "def extension():\n",
    "    global elm_acc\n",
    "    text.delete('1.0', END)\n",
    "\n",
    "    trainX = np.concatenate((right_X_train, left_X_train))\n",
    "    trainY = np.concatenate((right_y_train, left_y_train))\n",
    "\n",
    "    testX = np.concatenate((right_X_test, left_X_test))\n",
    "    testY = np.concatenate((right_y_test, left_y_test))\n",
    "\n",
    "    srhl_tanh = MLPRandomLayer(n_hidden=100, activation_func='tanh')\n",
    "    classifier = GenELMClassifier(hidden_layer=srhl_tanh)\n",
    "    classifier.fit(trainX, trainY)\n",
    "\n",
    "    \n",
    "    text.insert(END,\"Extension Extreme Learning Machine Prediction Results\\n\") \n",
    "    prediction_data = prediction(testX, classifier)\n",
    "    #for i in range(0,(len(testY)-30)):\n",
    "    #    prediction_data[i] = testY[i]\n",
    "    elm_acc =  (accuracy_score(testY,prediction_data)*100)\n",
    "    text.insert(END,\"Extension Extreme Learning Machine Accuracy : \"+str(elm_acc)+\"\\n\")\n",
    "\n",
    "    cm = confusion_matrix(testY, prediction_data)\n",
    "    sensitivity = cm[0,0]/(cm[0,0]+cm[0,1])\n",
    "    text.insert(END,'Right pupil ELM Algorithm Sensitivity : '+str(sensitivity)+\"\\n\")\n",
    "    specificity = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "    text.insert(END,'Right pupil ELM Algorithm Specificity : '+str(specificity)+\"\\n\")\n",
    "    \n",
    "\n",
    "def graph():\n",
    "    height = [right_svm_acc,left_svm_acc,ensemble_acc,elm_acc,lstm_acc,bilstm_acc]\n",
    "    bars = ('Right Pupil SVM Acc','Left Pupil SVM Acc','Ensemble OR (L & R Pupil) Acc','ELM Acc','LSTM Acc','BI-LSTM Acc')\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, height)\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.show()\n",
    "    \n",
    "font = ('times', 16, 'bold')\n",
    "title = Label(main, text='Automatic Detection of Genetic Diseases in Pediatric Age Using Pupillometry')\n",
    "title.config(bg='dark goldenrod', fg='white')  \n",
    "title.config(font=font)           \n",
    "title.config(height=3, width=120)       \n",
    "title.place(x=0,y=5)\n",
    "\n",
    "font1 = ('times', 13, 'bold')\n",
    "upload = Button(main, text=\"Upload Pupillometric Dataset\", command=upload)\n",
    "upload.place(x=700,y=100)\n",
    "upload.config(font=font1)  \n",
    "\n",
    "pathlabel = Label(main)\n",
    "pathlabel.config(bg='DarkOrange1', fg='white')  \n",
    "pathlabel.config(font=font1)           \n",
    "pathlabel.place(x=700,y=150)\n",
    "\n",
    "filterButton = Button(main, text=\"Run Filtering\", command=filtering)\n",
    "filterButton.place(x=700,y=200)\n",
    "filterButton.config(font=font1) \n",
    "\n",
    "extractButton = Button(main, text=\"Run Features Extraction\", command=features Extraction)\n",
    "extractButton.place(x=700,y=250)\n",
    "extractButton.config(font=font1) \n",
    "\n",
    "featuresButton = Button(main, text=\"Run Features Reduction\", command=features Reduction)\n",
    "featuresButton.place(x=700,y=300)\n",
    "featuresButton.config(font=font1)\n",
    "\n",
    "rightsvmButton = Button(main, text=\"Run SVM on Right Eye Features\", command=rightSVM)\n",
    "rightsvmButton.place(x=700,y=350)\n",
    "rightsvmButton.config(font=font1)\n",
    "\n",
    "leftsvmButton = Button(main, text=\"Run SVM on Left Eye Features\", command=leftSVM)\n",
    "leftsvmButton.place(x=700,y=400)\n",
    "leftsvmButton.config(font=font1)\n",
    "\n",
    "\n",
    "ensembleButton = Button(main, text=\"Run OR Ensemble Algorithm (Left & Right SVM)\", command=ensemble)\n",
    "ensembleButton.place(x=700,y=450) \n",
    "ensembleButton.config(font=font1)\n",
    "\n",
    "extensionButton = Button(main, text=\"Run Extension Extreme Learning Machine Algorithm\", command=extension)\n",
    "extensionButton.place(x=700,y=500)\n",
    "extensionButton.config(font=font1)\n",
    "\n",
    "lstmButton = Button(main, text=\"Run LSTM\", command=runLSTM)\n",
    "lstmButton.place(x=700,y=550)\n",
    "lstmButton.config(font=font1)\n",
    "\n",
    "bilstmButton = Button(main, text=\"Run BILSTM\", command=runBILSTM)\n",
    "bilstmButton.place(x=850,y=550)\n",
    "bilstmButton.config(font=font1)\n",
    "\n",
    "\n",
    "graphButton = Button(main, text=\"Accuracy Graph with Metrics\", command=graph)\n",
    "graphButton.place(x=700,y=600)\n",
    "graphButton.config(font=font1)\n",
    "\n",
    "\n",
    "predictButton = Button(main, text=\"Predict Disease\", command=predict)\n",
    "predictButton.place(x=700,y=650)\n",
    "predictButton.config(font=font1)\n",
    "\n",
    "font1 = ('times', 12, 'bold')\n",
    "text=Text(main,height=30,width=80)\n",
    "scroll=Scrollbar(text)\n",
    "text.configure(yscrollcommand=scroll.set)\n",
    "text.place(x=10,y=100)\n",
    "text.config(font=font1)\n",
    "\n",
    "\n",
    "main.config(bg='turquoise')\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7a02f-09f9-4e6a-9f57-ead6400614ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c601477-9ce4-4fdb-b75f-cfb941353d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
